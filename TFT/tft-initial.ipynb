{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6f363e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')  # avoid printing out absolute paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3db7f7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytorch-lightning\n",
    "# !pip install pytorch-forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f610dc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fe1afb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.rc('patch', force_edgecolor=True,edgecolor='black')\n",
    "plt.rc('hist', bins='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1ebc91",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f324bcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../wrangled_data/training_post_wrangle_small.csv')\n",
    "data.rename(columns={'date_block_num':'time_idx'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "137370bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'item_cnt_month':'volume'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ce9bdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['shop_id'] = data['shop_id'].astype('str')\n",
    "data['item_id'] = data['item_id'].astype('str')\n",
    "data['item_name'] = data['item_name'].astype('str')\n",
    "data['item_category_name'] = data['item_category_name'].astype('str')\n",
    "data['shop_name'] = data['shop_name'].astype('str')\n",
    "data['year'] = data['year'].astype('str')\n",
    "data['month'] = data['month'].astype('str')\n",
    "data['ID'] = data['ID'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55a341ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7282800 entries, 0 to 7282799\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   ID                  object \n",
      " 1   shop_id             object \n",
      " 2   item_id             object \n",
      " 3   year                object \n",
      " 4   month               object \n",
      " 5   volume              int64  \n",
      " 6   time_idx            int64  \n",
      " 7   mean_item           float64\n",
      " 8   mode_item           float64\n",
      " 9   item_name           object \n",
      " 10  item_category_id    int64  \n",
      " 11  item_category_name  object \n",
      " 12  shop_name           object \n",
      "dtypes: float64(2), int64(3), object(8)\n",
      "memory usage: 722.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5523c8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_ids=[\"agency\", \"sku\"]  # ['shop_id', 'item_id', 'item_name', 'item_category_name', 'shop_name']\n",
    "# static_categoricals=[\"agency\", \"sku\"] #['shop_id', 'item_id', 'item_name', 'item_category_name', 'shop_name']\n",
    "# static_reals=[\"avg_population_2017\", \"avg_yearly_household_income_2017\"] # ['mean_item', 'mode_item']\n",
    "# time_varying_known_categoricals=[\"special_days\", \"month\"]  # ['year', 'month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4952b1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pytorch_forecasting/data/encoders.py:621: UserWarning:\n",
      "\n",
      "scale is below 1e-7 - consider not centering the data or using data with higher variance for numerical stability\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_prediction_length = 6\n",
    "max_encoder_length = 24\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    data[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"volume\",\n",
    "    group_ids=['ID', 'shop_id', 'item_id'],\n",
    "    min_encoder_length=max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=['shop_id', 'item_id', 'item_name', 'item_category_name', 'shop_name'],\n",
    "    static_reals=['mean_item', 'mode_item'],\n",
    "    time_varying_known_categoricals=['year', 'month'],\n",
    "#     variable_groups={\"special_days\": special_days},  # group of categorical variables can be treated as one variable\n",
    "    time_varying_known_reals=[\"time_idx\"],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=[\n",
    "        \"volume\",\n",
    "#         \"log_volume\",\n",
    "#         \"industry_volume\",\n",
    "#         \"soda_volume\",\n",
    "#         \"avg_max_temp\",\n",
    "#         \"avg_volume_by_agency\",\n",
    "#         \"avg_volume_by_sku\",\n",
    "    ],\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=['ID', 'shop_id', 'item_id'], transformation=\"softplus\"\n",
    "    ),  # use softplus and normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    ")\n",
    "\n",
    "# create validation set (predict=True) which means to predict the last max_prediction_length points in time\n",
    "# for each series\n",
    "validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 128  # set this between 32 to 128\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=8)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9761303f",
   "metadata": {},
   "source": [
    "## Create Baseline Model\n",
    "\n",
    "Evaluating a Baseline model that predicts the next 6 months by simply repeating the last observed volume gives us a simle benchmark that we want to outperform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f48fdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning:\n",
      "\n",
      "Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.35832321643829346"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate baseline mean absolute error, i.e. predict next value as the last available value from the history\n",
    "actuals = torch.cat([y for x, (y, weight) in iter(val_dataloader)])\n",
    "baseline_predictions = Baseline().predict(val_dataloader)\n",
    "(actuals - baseline_predictions).abs().mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f2f5ab",
   "metadata": {},
   "source": [
    "## Train the Temporal Fusion Transformer\n",
    "\n",
    "It is now time to create our **TemporalFusionTransformer** model. We train the model with PyTorch Lightning.  \n",
    "\n",
    "## Find Optimal Learning Rate\n",
    "\n",
    "Prior to training, you can identify the optimal learning rate with the **PyTorch Lightning learning rate finder.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a8b8d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 187.4k\n"
     ]
    }
   ],
   "source": [
    "# configure network and trainer\n",
    "pl.seed_everything(42)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    # clipping gradients is a hyperparameter and important to prevent divergance\n",
    "    # of the gradient for recurrent neural networks\n",
    "    gradient_clip_val=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    # not meaningful for finding the learning rate but otherwise very important\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,  # most important hyperparameter apart from learning rate\n",
    "    # number of attention heads. Set to up to 4 for large datasets\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,  # between 0.1 and 0.3 are good values\n",
    "    hidden_continuous_size=8,  # set to <= hidden_size\n",
    "    output_size=7,  # 7 quantiles by default\n",
    "    loss=QuantileLoss(),\n",
    "    # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "565683c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning:\n",
      "\n",
      "The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pytorch_lightning/utilities/data.py:60: UserWarning:\n",
      "\n",
      "Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1280. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "\n",
      "Global seed set to 42\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning:\n",
      "\n",
      "The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ffd6fc6fdd34725853a055b6cfe8a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pytorch_lightning/utilities/data.py:60: UserWarning:\n",
      "\n",
      "Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 128. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "\n",
      "Restoring states from the checkpoint path at /home/ec2-user/SageMaker/Forecast_Product_Demand/TFT/lr_find_temp_model_6c7b00d3-df7a-47be-baec-6bc727b284aa.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suggested learning rate: 0.6456542290346551\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find optimal learning rate\n",
    "res = trainer.tuner.lr_find(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    max_lr=100.0,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e494ce66",
   "metadata": {},
   "source": [
    "For the **TemporalFusionTransformer**, the optimal learning rate seems to be slightly lower than the suggested one. Further, we do not directly want to use the suggested learning rate because PyTorch Lightning sometimes can get confused by the noise at lower learning rates and suggests rates far too low. Manual control is essential. We decide to pick 0.03 as learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c36fd38",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "If you have troubles training the model and get an error AttributeError: module `tensorflow._api.v2.io.gfile` has no attribute `get_filesystem`, consider either uninstalling tensorflow or first execute\n",
    "\n",
    "`import tensorflow as tf import tensorboard as tb tf.io.gfile = tb.compat.tensorflow_stub.io.gfile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d37ac498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 187.4k\n"
     ]
    }
   ],
   "source": [
    "# configure network and trainer\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=30,\n",
    "    gpus=1,\n",
    "    weights_summary=\"top\",\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=30,  # coment in for training, running valiation every 30 batches\n",
    "    # fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    "    log_every_n_steps=5\n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    output_size=7,  # 7 quantiles by default\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38fea330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 165 K \n",
      "3  | prescalers                         | ModuleDict                      | 128   \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 4.4 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 2.0 K \n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 1.4 K \n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K \n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K \n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K \n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K \n",
      "11 | lstm_encoder                       | LSTM                            | 2.2 K \n",
      "12 | lstm_decoder                       | LSTM                            | 2.2 K \n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544   \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 32    \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K \n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 1.1 K \n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 576   \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K \n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 576   \n",
      "20 | output_layer                       | Linear                          | 119   \n",
      "----------------------------------------------------------------------------------------\n",
      "187 K     Trainable params\n",
      "0         Non-trainable params\n",
      "187 K     Total params\n",
      "0.750     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning:\n",
      "\n",
      "The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pytorch_lightning/trainer/data_loading.py:433: UserWarning:\n",
      "\n",
      "The number of training samples (30) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a958a4ea69944892b9a846ed2d60fffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pytorch_lightning/utilities/data.py:60: UserWarning:\n",
      "\n",
      "Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 440. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6084da4b85f34ba8b9549f11f87acc34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning:\n",
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit network\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "#     enable_model_summary=False,\n",
    "#     enable_progress_bar = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e86703",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "Hyperparamter tuning with [optuna](https://optuna.org/) is directly build into pytorch-forecasting. For example, we can use the **optimize_hyperparameters()** function to optimize the TFTâ€™s hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebb5a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "# create study\n",
    "study = optimize_hyperparameters(\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    model_path=\"optuna_test\",\n",
    "    n_trials=200,\n",
    "    max_epochs=50,\n",
    "    gradient_clip_val_range=(0.01, 1.0),\n",
    "    hidden_size_range=(8, 128),\n",
    "    hidden_continuous_size_range=(8, 128),\n",
    "    attention_head_size_range=(1, 4),\n",
    "    learning_rate_range=(0.001, 0.1),\n",
    "    dropout_range=(0.1, 0.3),\n",
    "    trainer_kwargs=dict(limit_train_batches=30),\n",
    "    reduce_on_plateau_patience=4,\n",
    "    use_learning_rate_finder=False,  # use Optuna to find ideal learning rate or use in-built learning rate finder\n",
    ")\n",
    "\n",
    "# save study results - also we can resume tuning at a later point in time\n",
    "with open(\"test_study.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(study, fout)\n",
    "\n",
    "# show best hyperparameters\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5544321",
   "metadata": {},
   "source": [
    "## Evaluate Performance\n",
    "\n",
    "PyTorch Lightning automatically checkpoints training and thus, we can easily retrieve the best model and load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860357ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model according to the validation loss\n",
    "# (given that we use early stopping, this is not necessarily the last epoch)\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac62dd7b",
   "metadata": {},
   "source": [
    "After training, we can make predictions with **predict()**. The method allows very fine-grained control over what it returns so that, for example, you can easily match predictions to your pandas dataframe. See its documentation for details. We evaluate the metrics on the validation dataset and a couple of examples to see how well the model is doing. Given that we work with only 21 000 samples the results are very reassuring and can compete with results by a gradient booster. We also perform better than the baseline model. Given the noisy data, this is not trivial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4d5b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualte mean absolute error on validation set\n",
    "actuals = torch.cat([y[0] for x, y in iter(val_dataloader)])\n",
    "predictions = best_tft.predict(val_dataloader)\n",
    "(actuals - predictions).abs().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee61c81",
   "metadata": {},
   "source": [
    "We can now also look at sample predictions directly which we plot with **plot_prediction()**. As you can see from the figures below, forecasts look rather accurate. If you wonder, the grey lines denote the amount of attention the model pays to different points in time when making the prediction. This is a special feature of the Temporal Fusion Transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaadf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw predictions are a dictionary from which all kind of information including quantiles can be extracted\n",
    "raw_predictions, x = best_tft.predict(val_dataloader, mode=\"raw\", return_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b30f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(10):  # plot 10 examples\n",
    "    best_tft.plot_prediction(x, raw_predictions, idx=idx, add_loss_to_title=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0ddac9",
   "metadata": {},
   "source": [
    "## Worst Performers\n",
    "\n",
    "Looking at the worst performers, for example in terms of SMAPE, gives us an idea where the model has issues with forecasting reliably. These examples can provide important pointers about how to improve the model. This kind of actuals vs predictions plots are available to all models. Of course, it is also sensible to employ additional metrics, such as MASE, defined in the metrics module. However, for the sake of demonstration, we only use SMAPE here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb12130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualte metric by which to display\n",
    "predictions = best_tft.predict(val_dataloader)\n",
    "mean_losses = SMAPE(reduction=\"none\")(predictions, actuals).mean(1)\n",
    "indices = mean_losses.argsort(descending=True)  # sort losses\n",
    "for idx in range(10):  # plot 10 examples\n",
    "    best_tft.plot_prediction(\n",
    "        x, raw_predictions, idx=indices[idx], add_loss_to_title=SMAPE(quantiles=best_tft.loss.quantiles)\n",
    "    );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3ce634",
   "metadata": {},
   "source": [
    "## Actuals vs Predictions by Variables\n",
    "\n",
    "Checking how the model performs across different slices of the data allows us to detect weaknesses. Plotted below are the means of predictions vs actuals across each variable divided into 100 bins using the Now, we can directly predict on the generated data using the calculate_prediction_actual_by_variable() and plot_prediction_actual_by_variable() methods. The gray bars denote the frequency of the variable by bin, i.e. are a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292649cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, x = best_tft.predict(val_dataloader, return_x=True)\n",
    "predictions_vs_actuals = best_tft.calculate_prediction_actual_by_variable(x, predictions)\n",
    "best_tft.plot_prediction_actual_by_variable(predictions_vs_actuals);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b807ddb",
   "metadata": {},
   "source": [
    "## Predict on selected data\n",
    "\n",
    "To predict on a subset of data we can filter the subsequences in a dataset using the filter() method. Here we predict for the subsequence in the training dataset that maps to the group ids â€œAgency_01â€ and â€œSKU_01â€ and whose first predicted value corresponds to the time index â€œ15â€. We output all seven quantiles. This means we expect a tensor of shape `1 x n_timesteps x n_quantiles = 1 x 6 x 7` as we predict for a single subsequence six time steps ahead and 7 quantiles for each time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36a5426",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tft.predict(\n",
    "    training.filter(lambda x: (x.agency == \"Agency_01\") & (x.sku == \"SKU_01\") & (x.time_idx_first_prediction == 15)),\n",
    "    mode=\"quantiles\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a648d866",
   "metadata": {},
   "source": [
    "Of course, we can also plot this prediction readily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054a0758",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_prediction, x = best_tft.predict(\n",
    "    training.filter(lambda x: (x.agency == \"Agency_01\") & (x.sku == \"SKU_01\") & (x.time_idx_first_prediction == 15)),\n",
    "    mode=\"raw\",\n",
    "    return_x=True,\n",
    ")\n",
    "best_tft.plot_prediction(x, raw_prediction, idx=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0632fac6",
   "metadata": {},
   "source": [
    "## Predict on New Data\n",
    "\n",
    "Because we have covariates in the dataset, predicting on new data requires us to define the known covariates upfront."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed460518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
